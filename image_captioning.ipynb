{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_captioning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Ox4cgHYAL6HK","executionInfo":{"status":"ok","timestamp":1650739205402,"user_tz":-180,"elapsed":1368,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import os\n","import pandas as pd\n","import spacy\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","\n","spacy_eng = spacy.load('en')"]},{"cell_type":"code","source":["# Feature Extractor - Reteaua Neuronala Convolutionala care extrage features de dimensiunea embedding-ului dintr-o imagine\n","# si le utilizeaza in continuare in RNN pentru a face caption-ul pentru aceasta\n","class FeatureExtractorCNN(nn.Module):\n","    def __init__(self, embedding_size, continue_training=False):\n","        super(FeatureExtractorCNN, self).__init__()\n","        self.continue_training = continue_training\n","        self.extractor = torchvision.models.inception_v3(pretrained=True)\n","        self.extractor.fc = nn.Linear(in_features=self.extractor.fc.in_features, out_features=embedding_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(0.25)\n","    \n","    def forward(self, x):\n","        features = self.extractor(x).logits\n","\n","        for name, parameters in self.extractor.named_parameters():\n","            if \"fc.weight\" in name or \"fc.bias\" in name:\n","                parameters.require_grad = True\n","            else:\n","                parameters.require_grad = self.continue_training\n","\n","        return self.dropout(self.activation(features))"],"metadata":{"id":"DcTE-cmUL-IK","executionInfo":{"status":"ok","timestamp":1650739205403,"user_tz":-180,"elapsed":5,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# CaptioningRNN - Retea Neuronala Recurenta care utilizeaza features-urile obtinute din imaginea de input si,\n","# utilizand mai multe layere de LSTM (long short-term memory) selecteaza cele mai potrivite cuvinte care ar\n","# putea alcatui un caption corect pentru input-ul nostru\n","class CaptioningRNN(nn.Module):\n","    def __init__(self, embedding_size, hidden_size, vocabulary_size, layer_number):\n","        super(CaptioningRNN, self).__init__()\n","        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_size)\n","        self.lstm = nn.LSTM(embedding_size, hidden_size, layer_number)\n","        self.fc = nn.Linear(in_features=hidden_size, out_features=vocabulary_size)\n","        self.dropout = nn.Dropout(0.25)\n","    \n","    def forward(self, features, captions):\n","        embeddings = self.embedding(captions)\n","        embeddings = self.dropout(embeddings)\n","        embeddings = torch.cat((features.unsqueeze(0), embeddings), dim=0)\n","        \n","        hidden_output, _ = self.lstm(embeddings)\n","        output = self.fc(hidden_output)\n","        return output"],"metadata":{"id":"EDvFyjicL-Fo","executionInfo":{"status":"ok","timestamp":1650739205403,"user_tz":-180,"elapsed":5,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ImageCaptioningNet - Retea Neuronala care combina cele doua tipuri de retele neuronale\n","# de mai sus - CNN si RNN pentru a crea descrieri pentru pozele noastre\n","class ImageCaptioningNet(nn.Module):\n","    def __init__(self, embedding_size, hidden_size, vocabulary_size, layer_number, continue_training=False):\n","        super(ImageCaptioningNet, self).__init__()\n","        self.feature_extractor_cnn = FeatureExtractorCNN(embedding_size, continue_training)\n","        self.captioning_rnn = CaptioningRNN(embedding_size, hidden_size, vocabulary_size, layer_number)\n","    \n","    def forward(self, images, captions):\n","        features = self.feature_extractor_cnn(images)\n","        output = self.captioning_rnn(features, captions)\n","        return output\n","    \n","    def generate_caption(self, image, vocabulary, max_length=50):\n","        caption = []\n","        with torch.no_grad():\n","            out = self.feature_extractor_cnn(image).unsqueeze(0)\n","            states = None\n","\n","            for _ in range(max_length):\n","                hidden_output, states = self.captioning_rnn.lstm(out, states)\n","                output = self.captioning_rnn.linear(hidden_output.squeeze(0))\n","                \n","                predicted_word = output.argmax(dim=1)\n","                caption.append(predicted_word.item())\n","                out = self.captioning_rnn.embedding(predicted_word).unsqueeze(0)\n","\n","                if vocabulary.itos[predicted_word.item()] == \"<EOS>\":\n","                    break\n","        \n","        return [vocabulary.itos[word_idx] for word_idx in caption]"],"metadata":{"id":"Hjnn0LvXL-C1","executionInfo":{"status":"ok","timestamp":1650739205404,"user_tz":-180,"elapsed":5,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Antrenarea\n","<br>\n","Mai intai, descarcam setul de imagini si titluri de pe kaggle si o dezarhivam. Pentru asta, e nevoie de incarcat kaggle.json care contine cheia privata a unui cont kaggle."],"metadata":{"id":"Xmrk2mWReriU"}},{"cell_type":"code","source":["!pip install kaggle\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n"],"metadata":{"id":"QIJcXmcinq1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d aladdinpersson/flickr8kimagescaptions"],"metadata":{"id":"QvMs9IJoun3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip flickr8kimagescaptions.zip "],"metadata":{"id":"-VkahVaZw2n4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pregatirea datelor\n","\n","Pentru a putea utiliza datele descarcate, e nevoie de normalizat titlurile si mapat la valori numerice. Pentru a face asta, in prealabil vom crea vocabularul tuturor cuvintelor prezente in titlurile de antrenare. Vocabularul va reprezenta o mapare dintre cuvintele tokenizate si indexurile sale. De asemenea, se vor adauga inca 4 \"cuvinte\" in vocabular:\n","1. '\\<PAD>': token adaugat la sfarsitul titlurilor mai scurte pentru ca toate titlurile din un batch sa aiba acelasi numar de tokenuri;\n","2. '\\<SOS>': tokenul care reprezinta inceputul titlului;\n","3. '\\<EOS>': tokenul care reprezinta sfarsitul titlului;\n","4. '\\<UNK>': tokenul care se pune in locul cuvintelor care nu fac parte din vocabular.\n","\n","Un token (cuvant) nu va fi adaugat in vocabular daca in toate titlurile acesta se intalneste mai putin de `freq_threshold` ori.\n","\n"],"metadata":{"id":"SrkidktjnpS4"}},{"cell_type":"code","source":["class Vocabulary:\n","  def __init__(self, freq_threshold):\n","    # initializam maparile dintre tokenuri si indexul sau si invers\n","    # adaugam tokenurile speciale la initializare\n","    self.idx_str_dict = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3:'<UNK>'}\n","    self.str_idx_dict = {'<PAD>':0, '<SOS>':1, '<EOS>':2, '<UNK>':3}\n","    self.freq_threshold = freq_threshold\n","\n","  def __len__(self):\n","    return len(self.idx_str_dict)\n","\n","  @staticmethod\n","  def tokenizer(text):\n","    \"\"\"\n","    Functie statica care primeste un string care reprezinta o propozitie in engleza\n","    si returneaza o lista de stringuri care reprezinta tokenizarea acesteea.\n","    \"\"\"\n","    return [token.text.lower() for token in spacy_eng.tokenizer(text)]\n","\n","  def build_vocabulary(self, sentences):\n","    \"\"\"\n","    sunt parcurse si tokenizate titlurile si sunt pastrate cele care apar mai mult de `freq_threshold` ori\n","    \"\"\"\n","    frequencies = {}\n","    index = 4\n","    for sentence in sentences:\n","      for word in self.tokenizer(sentence):\n","        if word not in frequencies:\n","          frequencies[word] = 1\n","        else:\n","          frequencies[word] += 1\n","    \n","    for word, freq in frequencies.items():\n","      if freq >= self.freq_threshold:\n","        self.str_idx_dict[word] = index\n","        self.idx_str_dict[index] = word\n","        index += 1\n","\n","  def normalize(self, text):\n","    \"\"\"\n","    Primeste un titlu pe care il tokenizeaza si returneaza lista tokenilor.\n","    Tokenurile care nu sunt prezente in vocabular sunt inlocuite cu '<UNK>'\n","    \"\"\"\n","    tokenized_text = self.tokenizer(text)\n","\n","    return [\n","      self.str_idx_dict[token] if token in self.str_idx_dict else self.str_idx_dict['<UNK>']\n","      for token in tokenized_text \n","    ]\n"],"metadata":{"id":"rImJ4uGD00f1","executionInfo":{"status":"ok","timestamp":1650739211508,"user_tz":-180,"elapsed":9,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class FlickrDataset(Dataset):\n","  def __init__(self, root_dir, captions_file, transform=None, freq_threshold=5):\n","    self.root_dir = root_dir\n","    self.dataframe = pd.read_csv(captions_file)\n","    self.transform = transform\n","    \n","    self.images = self.dataframe['image']\n","    self.captions = self.dataframe['caption']\n","\n","    self.vocabulary = Vocabulary(freq_threshold)\n","    self.vocabulary.build_vocabulary(self.captions.tolist())\n","\n","  def __len__(self):\n","    return len(self.dataframe)\n","\n","  def __getitem__(self, index):\n","    caption = self.captions[index]\n","    image_id = self.images[index]\n","    image = Image.open(os.path.join(self.root_dir, image_id)).convert('RGB')\n","\n","    if self.transform is not None:\n","      image = self.transform(image)\n","    \n","    normalized_caption = [self.vocabulary.str_idx_dict['<SOS>']] # start of sentence\n","    normalized_caption += self.vocabulary.normalize(caption)\n","    normalized_caption.append(self.vocabulary.str_idx_dict['<EOS>']) # end of sencence\n","\n","    return image, torch.tensor(normalized_caption)"],"metadata":{"id":"lLC9rRAQyaaJ","executionInfo":{"status":"ok","timestamp":1650739211510,"user_tz":-180,"elapsed":9,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Collate:\n","  \"\"\"\n","  Clasa care adauga padding la toate titlurile dintr-un batch pentru a le face de aceeasi lungime\n","  \"\"\"\n","  def __init__(self, pad_idx):\n","    self.pad_idx = pad_idx\n","    \n","  def __call__(self, batch):\n","    images = [item[0].unsqueeze(0) for item in batch] # a dimensiune aditionala pentru concatenare\n","    images = torch.cat(images, dim=0)\n","    targets = [item[1] for item in batch]\n","    targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n","\n","    return images, targets"],"metadata":{"id":"d_5eWTf64fFp","executionInfo":{"status":"ok","timestamp":1650739214082,"user_tz":-180,"elapsed":2,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_dataloader(\n","    root_dir,\n","    annotation_file,\n","    transform,\n","    batch_size=32,\n","    num_workers=2,\n","    shuffle=True, \n","    pin_memory=True\n","):\n","  \"\"\"\n","  Initializeaza un Dataset, completeaza vocabularul si pe baza Datasetului creaza un DataLoader\n","  \"\"\"\n","  dataset = FlickrDataset(root_dir, annotation_file, transform=transform)\n","  \n","  pad_idx = dataset.vocabulary.str_idx_dict['<PAD>']\n","\n","  dataloader = DataLoader(\n","      dataset=dataset,\n","      batch_size=batch_size,\n","      num_workers=num_workers,\n","      shuffle=shuffle,\n","      pin_memory=pin_memory,\n","      collate_fn=Collate(pad_idx)\n","  )\n","\n","  return dataloader, dataset"],"metadata":{"id":"McKPlBtS7WB2","executionInfo":{"status":"ok","timestamp":1650739413419,"user_tz":-180,"elapsed":402,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["!ls "],"metadata":{"id":"V81O9x7j9nFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","transform = transforms.Compose(\n","    [\n","      transforms.Resize((224, 224)),\n","      transforms.ToTensor()\n","    ]\n",")\n","dataloader, _ = get_dataloader('flickr8k/images/', annotation_file='flickr8k/captions.txt', transform=transform)\n","\n","stop_at = 10\n","print(len(dataloader))\n","for index, (images, captions) in enumerate(dataloader):\n","  if index == stop_at:\n","    break\n","\n","  print(images.shape)\n","  print(captions.shape)"],"metadata":{"id":"_Ov0aSIO9A4Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Functia de antrenare"],"metadata":{"id":"sVctUh66nlkN"}},{"cell_type":"code","source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def train(\n","    model,\n","    dataloader,\n","    loss_fn,\n","    optimizer,\n","    epochs\n","):\n","  model.train()\n","\n","  for epoch in range(epochs):\n","\n","    total_loss = 0\n","\n","    for idx, (images, captions) in enumerate(tqdm(dataloader)):\n","      images = images.to(DEVICE)\n","      captions = captions.to(DEVICE)\n","\n","      outputs = model(images, captions[:-1])\n","      loss = loss_fn(outputs.reshape(-1, outputs.shape[2]), captions.reshape(-1))\n","      total_loss += loss\n","      optimizer.zero_grad()\n","      loss.backward(loss)\n","      optimizer.step()\n","    \n","    print(f'Epoca {epoch}, Avg loss: {total_loss/len(dataloader)}')\n","    torch.save(model.state_dict(), './model_last.pt')\n","\n","  return model\n","\n","\n"],"metadata":{"id":"ZBGN19VdL99f","executionInfo":{"status":"ok","timestamp":1650739782277,"user_tz":-180,"elapsed":4,"user":{"displayName":"DANIEL AVRAM","userId":"07547434767383765451"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [\n","      transforms.Resize((356, 356)),\n","      transforms.RandomCrop((299, 299)),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ] \n",")\n","\n","dataloader, dataset = get_dataloader(\n","    root_dir='flickr8k/images',\n","    annotation_file='flickr8k/captions.txt',\n","    num_workers=2,\n","    transform=transform\n",")\n","\n","embedding_size = 256\n","hidden_size = 256\n","vocabulary_size = len(dataset.vocabulary)\n","layer_number = 1\n","lr = 3e-4\n","epochs = 10\n","\n","model = ImageCaptioningNet(\n","    embedding_size=embedding_size,\n","    hidden_size=hidden_size,\n","    vocabulary_size=vocabulary_size,\n","    layer_number=layer_number,\n","    continue_training=True\n",")\n","\n","model.to(DEVICE)\n","\n","\n","\n","loss_fn = nn.CrossEntropyLoss(ignore_index=dataset.vocabulary.str_idx_dict['<PAD>'])\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","\n","train(\n","    model=model,\n","    dataloader=dataloader,\n","    loss_fn=loss_fn,\n","    optimizer=optimizer,\n","    epochs=epochs\n",")"],"metadata":{"id":"DBTu_kDVL96s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"dXmACszYL94C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"87HZAb71L91I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5rhvzInrL9yU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"jHTU4QysL9vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Wh8DmAKCL9sz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ReW5AyzWL9qE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FyjbXbLsL9nb"},"execution_count":null,"outputs":[]}]}